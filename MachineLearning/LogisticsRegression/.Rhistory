install.packages("forecast")
install.packages("ggplot2")
install.packages("dplyr")
library("colorspace", lib.loc="~/R/win-library/3.3")
detach("package:colorspace", unload=TRUE)
library("tseries", lib.loc="~/R/win-library/3.3")
install.packages("tibble")
install.packages("car")
library(rpart)
cols = c(1,6,13:15)
bankdata[,cols] = as.integer(as.character(unlist((bankdata[,cols]))))
cols= c(2:5,7:9,11,13,16)
bankdata[,cols] = lapply(bankdata[,cols],factor)
library(rpart)
bankdata = read.csv(filepath)
str(bankdata)
cols = c(1,6,13:15)
bankdata[,cols] = as.integer(as.character(unlist((bankdata[,cols]))))
cols= c(2:5,7:9,11,13,16)
bankdata[,cols] = lapply(bankdata[,cols],factor)
filepath = "E:/Git/rprojects/MachineLearning/DecisionTree/bank.csv"
library(rpart)
bankdata = read.csv(filepath)
str(bankdata)
cols = c(1,6,13:15)
bankdata[,cols] = as.integer(as.character(unlist((bankdata[,cols]))))
cols= c(2:5,7:9,11,13,16)
bankdata[,cols] = lapply(bankdata[,cols],factor)
bankdata$day = NULL
bankdata$duration =NULL
bankTree = rpart(y~.,data=bankdata,method='class',
control =rpart.control(minsplit = 65, cp=0.0001))
plot(bankTree)
text(bankTree,pretty = TRUE)
xvals = seq(i*seglength+deltat,(i+1)*seglength-delta,length.out = segpoints)
for(i in c(0:2))
{
xvals = seq(i*seglength+deltat,(i+1)*seglength-delta,length.out = segpoints)
}
library(rpart)
seglength <- 1000
delta <- 100
segpoints <- 20
yref <- 10
for(i in c(0:2)){
xvals = seq(i*seglength+deltat,(i+1)*seglength-delta,length.out = segpoints)
ybase = if(i==1) yref else 2*yref
yvals = ybase + rnorm(segpoints)
newrows = cbind(xvals,yvals)
df = rbind(df,newrows)
}
for(i in c(0:2)){
xvals = seq(i*seglength+deltat,(i+1)*seglength-delta,length.out = segpoints)
ybase = if(i==1) yref else 2*yref
yvals = ybase + rnorm(segpoints)
newrows = cbind(xvals,yvals)
df = rbind(df,newrows)
}
library(rpart)
seglength <- 1000
delta <- 100
segpoints <- 20
yref <- 10
for(i in c(0:2)){
xvals = seq(i*seglength+deltat,(i+1)*seglength-delta,length.out = segpoints)
ybase = if(i==1) yref else 2*yref
yvals = ybase + rnorm(segpoints)
newrows = cbind(xvals,yvals)
df = rbind(df,newrows)
}
for(i in c(0:2)){
xvals = seq(i*seglength+delta,(i+1)*seglength-delta,length.out = segpoints)
ybase = if(i==1) yref else 2*yref
yvals = ybase + rnorm(segpoints)
newrows = cbind(xvals,yvals)
df = rbind(df,newrows)
}
for(i in c(0:2)){
xvals = seq(i*seglength+delta,(i+1)*seglength-delta,length.out = segpoints)
ybase = if(i==1) yref else 2*yref
yvals = ybase + rnorm(segpoints)
newrows = cbind(xvals,yvals)
#df = rbind(df,newrows)
}
df <- data.frame("x"=numeric(),"y"=numeric())
df = rbind(df,newrows)
for(i in c(0:2)){
xvals = seq(i*seglength+delta,(i+1)*seglength-delta,length.out = segpoints)
ybase = if(i==1) yref else 2*yref
yvals = ybase + rnorm(segpoints)
newrows = cbind(xvals,yvals)
df = rbind(df,newrows)
}
df
name(df) <- c('x','y')
names(df) <- c('x','y')
plot(df)
plot(df$x,df$y,ylab = 'Y',xlab = 'X')
dftree = rpart(y~x,data=df,method = 'anova')
plot(dftree)
text(dftree)
heartTree = rpart(heart.disease ~ ., data=heart,method = 'class',
control =rpart.control(minsplit = 1, cp=0.0001))
filepath = "E:/Git/rprojects/MachineLearning/DecisionTree/heart.csv"
library(rpart)
heart=read.csv(filepath,sep="")
str(heart)
cols = c(1,4,5,8,10,12)
heart[,cols] = as.numeric(as.character(unlist(heart[,cols])))
cols = c(2,3,6,7,9,13)
heart[,cols] = lapply(heart[,cols],factor)
cols = c(11)
heart[,cols] = as.integer(as.character(unlist(heart[,cols])))
heartTree = rpart(heart.disease ~ ., data=heart,method = 'class')
plot(heartTree)
text(heartTree,pretty = T)
heartTree = rpart(heart.disease ~ ., data=heart,method = 'class',
control =rpart.control(minsplit = 1, cp=0.0001))
plot(heartTree)
text(heartTree,pretty = T)
heartTree = rpart(heart.disease ~ ., data=heart,method = 'class')
plot(heartTree)
text(heartTree,pretty = T)
fancyRpartPlot(rxAddInheritance(heartTree))
library(rattle)
install.packages(rattle)
install.packages('rattle')
library(rattle)
library(rattle)
fancyRpartPlot(rxAddInheritance(heartTree))
library(rpart.plot)
install.packages('rpart.plot')
fancyRpartPlot(rxAddInheritance(heartTree))
install.packages('RColorBrewer')
library(RColorBrewer)
fancyRpartPlot(rxAddInheritance(heartTree))
install.packages('party')
install.packages('partyKit')
install.packages('partykit')
library(partykit)
fancyRpartPlot(rxAddInheritance(heartTree))
library(caret)
install.packages('caret')
library(caret)
fancyRpartPlot(rxAddInheritance(heartTree))
fancyRpartPlot(heartTree)
filepath = "E:/Git/rprojects/MachineLearning/DecisionTree/heart.csv"
library(rpart)
heart=read.csv(filepath,sep="")
str(heart)
cols = c(1,4,5,8,10,12)
heart[,cols] = as.numeric(as.character(unlist(heart[,cols])))
cols = c(2,3,6,7,9,13)
heart[,cols] = lapply(heart[,cols],factor)
cols = c(11)
heart[,cols] = as.integer(as.character(unlist(heart[,cols])))
heartTree = rpart(heart.disease ~ ., data=heart,method = 'class')
plot(heartTree)
text(heartTree,pretty = T)
library(rattle)
library(rpart.plot)
library(RColorBrewer)
fancyRpartPlot(heartTree)
log(2,base = 2)
0.02*log(0.02,base = 2) + .98*log(.98,2) + .6*log(.6,2) + .4*log(.4,2)
(-1/2)*(0.02*log(0.02,base = 2) + .98*log(.98,2) + .6*log(.6,2) + .4*log(.4,2))
censes = read.csv("E:/Upgrade-DA/3. Predictive Analytics I/1. Data Prepration/1. Data Cleaning/census income11.csv",
stringsAsFactors = F)
setwd("E:\\Git\\rprojects\\MachineLearning\\LogisticsRegression")
baseball = read.csv("baseball.csv")
summary(baseball)
sum(is.na(baseball))
set.seed(100)
s= sample(1:nrow(baseball_runs),0.7*nrow(baseball))
s= sample(1:nrow(baseball),0.7*nrow(baseball))
base_train = baseball_runs[s,]
base_train = baseball_runs[s,]
base_train = baseball[s,]
base_test = baseball[-s,]
s
model_runs = glm(Playoffs ~ RS, family = binomial,data=base_train)
summary(model_runs)
set.seed(2)
s= sample(1:nrow(baseball),0.7*nrow(baseball))
base_train = baseball[s,]
base_test = baseball[-s,]
model_runs = glm(Playoffs ~ RS, family = binomial,data=base_train)
summary(model_runs)
pred_runs = predict(model_runs,base_test)
base_test$pred = pred_runs
table(base_test$Playoffs,base_test$pred)
base_test$pred = ifelse(pred_runs>.5, "Yes","No")
table(base_test$Playoffs,base_test$pred)
View(base_test)
base_test$pred = ifelse(pred_runs>.4, "Yes","No")
table(base_test$Playoffs,base_test$pred)
base_test$pred = ifelse(pred_runs>.3, "Yes","No")
table(base_test$Playoffs,base_test$pred)
base_test$pred = ifelse(pred_runs>.2, "Yes","No")
table(base_test$Playoffs,base_test$pred)
base_test$pred = ifelse(pred_runs>.1, "Yes","No")
table(base_test$Playoffs,base_test$pred)
base_test$pred = ifelse(pred_runs>.8, "Yes","No")
table(base_test$Playoffs,base_test$pred)
base_test$pred = ifelse(pred_runs>.08, "Yes","No")
table(base_test$Playoffs,base_test$pred)
base_test$pred = ifelse(pred_runs>.03, "Yes","No")
table(base_test$Playoffs,base_test$pred)
base_test$pred = ifelse(pred_runs>.01, "Yes","No")
table(base_test$Playoffs,base_test$pred)
base_test$pred = ifelse(pred_runs>.005, "Yes","No")
table(base_test$Playoffs,base_test$pred)
base_test$pred = ifelse(pred_runs>.0005, "Yes","No")
table(base_test$Playoffs,base_test$pred)
base_test$pred_prob = pred_runs
pred_runs = predict(model_runs,base_test,type="response")
base_test$pred = ifelse(pred_runs>.5, "Yes","No")
base_test$pred_prob = pred_runs
table(base_test$Playoffs,base_test$pred)
base_test$pred = ifelse(pred_runs>.2, "Yes","No")
base_test$pred_prob = pred_runs
table(base_test$Playoffs,base_test$pred)
base_test$pred = ifelse(pred_runs>.1, "Yes","No")
base_test$pred_prob = pred_runs
table(base_test$Playoffs,base_test$pred)
base_test$pred = ifelse(pred_runs>.3, "Yes","No")
table(base_test$Playoffs,base_test$pred)
base_test$pred = ifelse(pred_runs>.3, "Yes","No")
base_test$pred_prob = pred_runs
table(base_test$Playoffs,base_test$pred)
base_test$pred = ifelse(pred_runs>.1, "Yes","No")
base_test$pred_prob = pred_runs
table(base_test$Playoffs,base_test$pred)
filepath="E:\\Git\\rprojects\\MachineLearning\\LogisticsRegression"
setwd(fileP)
setwd(filepath)
baseball = read.csv("baseball_allAttributes.csv")
summary(baseball)
str(baseball)
is.na(baseball)
sum(is.na(baseball))
set.seed(2)
s=sample(0:nrow(baseball),.3)
train_baseball = baseball[s,]
test_baseball = baseball[-s,]
s=sample(0:nrow(baseball),SplitRatio=.5)
quantile(baseball$RS,c(.95,.96,.97,.98,.99,1))
quantile(baseball$Team,c(.95,.96,.97,.98,.99,1))
quantile(baseball$Team,c(.95,.96,.97,.98,.99,1))
quantile(baseball$Team,c(.95,.96,.97,.98,.99,1))
quantile(baseball$RA,c(.95,.96,.97,.98,.99,1))
quantile(baseball$OBP,c(.95,.96,.97,.98,.99,1))
quantile(baseball$SLG,c(.95,.96,.97,.98,.99,1))
quantile(baseball$BA,c(.95,.96,.97,.98,.99,1))
quantile(baseball$Playoffs,c(.95,.96,.97,.98,.99,1))
set.seed(1000)
library(caTools)
s=sample.split(0:nrow(baseball),SplitRatio=.7)
train_baseball = baseball[s,]
test_baseball = baseball[-s,]
View(test_baseball)
table(s)
test_baseball = baseball[-s,]
test_baseball = baseball[!s,]
initial_model = glm(Playoffs ~ ., data=train_baseball[,-1])
initial_model = glm(Playoffs ~ ., data=train_baseball[,-1],family = "binomial")
summary()
summary(initial_model)
best_model = step(initial_model,direction = "both")
library(car)
vif(best_model)
vif(best_model)
summary(best_model)
vif(best_model)
model2 = glm(Playoffs ~ RS +RA+SLG, data = baseball,family = "binomial")
vif(model2)
summary(model2)
vif(model2)
model3 = glm(Playoffs ~ RS + RA, data=baseball, family = "binomial")
summary(model3)
vif(model3)
model_final=model_3
model_final=model3
